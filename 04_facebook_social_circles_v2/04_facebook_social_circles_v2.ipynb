{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065715a6",
   "metadata": {},
   "source": [
    "# Facebook Social Circles V2\n",
    "Link: https://snap.stanford.edu/data/ego-Facebook.html\n",
    "\n",
    ">This dataset consists of 'circles' (or 'friends lists') from Facebook. Facebook data was collected from survey participants using this Facebook app.\n",
    "\n",
    "---\n",
    "\n",
    "Focus: Integrating node-level features with scaled Logistic Regression; optimizing via basic hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3bd9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import negative_sampling as ns, splits, plot\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import average_precision_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c360fd5",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ece06d",
   "metadata": {},
   "source": [
    "This dataset is an ego network, meaning that it centers around a specific user (the \"ego\") and includes all their immediate friends and the connections between those friends.\n",
    "There are several file types:\n",
    "- `.edges`: These files define the edges within a specific ego network.\n",
    "- `.feat`: These files contain anonymized binary features for all nodes in the ego network (except the ego itself). Each line starts with a node ID, followed by a series of binary (0 or 1) feature values, space-separated.\n",
    "- `.egofeat`: These files contain the anonymized binary features for the ego node itself.\n",
    "- `.featnames`: Provides a mapping for the feature indices. Each line describes a feature. Due to anonymization, the descriptions are generic.\n",
    "- `.circles`: Defines \"circles\" or \"friend lists\" within the ego network (ground-truth communities). Each line starts with a label, followed by a list of space-separated node IDs that belong to that circle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f823a89",
   "metadata": {},
   "source": [
    "For learning purposes this notebook will focus on just one ego network (of node `0`) from all the ego networks available in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0945053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Graph\n",
    "G = nx.read_edgelist('data/0.edges', nodetype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b57ec95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['birthday;anonymized feature 0',\n",
       " 'birthday;anonymized feature 1',\n",
       " 'birthday;anonymized feature 2',\n",
       " 'birthday;anonymized feature 3',\n",
       " 'birthday;anonymized feature 4',\n",
       " 'birthday;anonymized feature 5',\n",
       " 'birthday;anonymized feature 6',\n",
       " 'birthday;anonymized feature 7',\n",
       " 'education;classes;id;anonymized feature 8',\n",
       " 'education;classes;id;anonymized feature 9']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Features Names\n",
    "feature_path = 'data/0.feat'\n",
    "feature_names_path = 'data/0.featnames'\n",
    "egofeat_path = \"data/0.egofeat\"\n",
    "\n",
    "feature_names = []\n",
    "try:\n",
    "    with open(feature_names_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            parts = line.split(' ', 1)  # Separate indexes\n",
    "            feature_names.append(parts[1])\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading feature names: {e}\")\n",
    "    feature_names = []\n",
    "\n",
    "feature_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec4f448",
   "metadata": {},
   "source": [
    "Feature vectors from this dataset has been obscured, so each feature real value has been replaced. For instance, a feature \"political=Democratic Party\", would be replaced with \"political=anonymized feature 1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7bac2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birthday;anonymized feature 0</th>\n",
       "      <th>birthday;anonymized feature 1</th>\n",
       "      <th>birthday;anonymized feature 2</th>\n",
       "      <th>birthday;anonymized feature 3</th>\n",
       "      <th>birthday;anonymized feature 4</th>\n",
       "      <th>birthday;anonymized feature 5</th>\n",
       "      <th>birthday;anonymized feature 6</th>\n",
       "      <th>birthday;anonymized feature 7</th>\n",
       "      <th>education;classes;id;anonymized feature 8</th>\n",
       "      <th>education;classes;id;anonymized feature 9</th>\n",
       "      <th>...</th>\n",
       "      <th>work;start_date;anonymized feature 200</th>\n",
       "      <th>work;start_date;anonymized feature 201</th>\n",
       "      <th>work;start_date;anonymized feature 168</th>\n",
       "      <th>work;start_date;anonymized feature 202</th>\n",
       "      <th>work;start_date;anonymized feature 169</th>\n",
       "      <th>work;start_date;anonymized feature 170</th>\n",
       "      <th>work;start_date;anonymized feature 171</th>\n",
       "      <th>work;start_date;anonymized feature 203</th>\n",
       "      <th>work;start_date;anonymized feature 204</th>\n",
       "      <th>work;with;id;anonymized feature 205</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    birthday;anonymized feature 0  birthday;anonymized feature 1  \\\n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "5                               0                              0   \n",
       "6                               0                              1   \n",
       "7                               0                              0   \n",
       "8                               0                              0   \n",
       "9                               0                              0   \n",
       "10                              0                              0   \n",
       "\n",
       "    birthday;anonymized feature 2  birthday;anonymized feature 3  \\\n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "5                               0                              0   \n",
       "6                               0                              0   \n",
       "7                               0                              0   \n",
       "8                               0                              0   \n",
       "9                               0                              0   \n",
       "10                              0                              0   \n",
       "\n",
       "    birthday;anonymized feature 4  birthday;anonymized feature 5  \\\n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "5                               0                              0   \n",
       "6                               0                              0   \n",
       "7                               0                              0   \n",
       "8                               0                              0   \n",
       "9                               0                              0   \n",
       "10                              0                              0   \n",
       "\n",
       "    birthday;anonymized feature 6  birthday;anonymized feature 7  \\\n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              1   \n",
       "4                               0                              0   \n",
       "5                               0                              0   \n",
       "6                               0                              0   \n",
       "7                               0                              0   \n",
       "8                               0                              0   \n",
       "9                               0                              0   \n",
       "10                              1                              0   \n",
       "\n",
       "    education;classes;id;anonymized feature 8  \\\n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "5                                           0   \n",
       "6                                           0   \n",
       "7                                           0   \n",
       "8                                           0   \n",
       "9                                           0   \n",
       "10                                          0   \n",
       "\n",
       "    education;classes;id;anonymized feature 9  ...  \\\n",
       "1                                           0  ...   \n",
       "2                                           0  ...   \n",
       "3                                           0  ...   \n",
       "4                                           0  ...   \n",
       "5                                           0  ...   \n",
       "6                                           0  ...   \n",
       "7                                           0  ...   \n",
       "8                                           0  ...   \n",
       "9                                           0  ...   \n",
       "10                                          0  ...   \n",
       "\n",
       "    work;start_date;anonymized feature 200  \\\n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "10                                       1   \n",
       "\n",
       "    work;start_date;anonymized feature 201  \\\n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "10                                       0   \n",
       "\n",
       "    work;start_date;anonymized feature 168  \\\n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "10                                       0   \n",
       "\n",
       "    work;start_date;anonymized feature 202  \\\n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        1   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "10                                       0   \n",
       "\n",
       "    work;start_date;anonymized feature 169  \\\n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "10                                       0   \n",
       "\n",
       "    work;start_date;anonymized feature 170  \\\n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "10                                       0   \n",
       "\n",
       "    work;start_date;anonymized feature 171  \\\n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "10                                       0   \n",
       "\n",
       "    work;start_date;anonymized feature 203  \\\n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "10                                       0   \n",
       "\n",
       "    work;start_date;anonymized feature 204  \\\n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "10                                       0   \n",
       "\n",
       "    work;with;id;anonymized feature 205  \n",
       "1                                     0  \n",
       "2                                     0  \n",
       "3                                     0  \n",
       "4                                     0  \n",
       "5                                     0  \n",
       "6                                     0  \n",
       "7                                     0  \n",
       "8                                     0  \n",
       "9                                     0  \n",
       "10                                    0  \n",
       "\n",
       "[10 rows x 224 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Features Values\n",
    "node_ids = []\n",
    "feature_data_rows = []\n",
    "expected_num_features = len(feature_names)\n",
    "\n",
    "try:\n",
    "    with open(feature_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            parts = line.split(' ')\n",
    "\n",
    "            node_id = int(parts[0])\n",
    "\n",
    "            feat_values = [int(val) for val in parts[1:]]\n",
    "\n",
    "            node_ids.append(node_id)\n",
    "            feature_data_rows.append(feat_values)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading feature data: {e}\")\n",
    "\n",
    "# Create Dataframe\n",
    "features_df = pd.DataFrame(feature_data_rows, columns=feature_names, index=node_ids)\n",
    "features_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8ab1be",
   "metadata": {},
   "source": [
    "The features DataFrame utilizes **one-hot encoding**, a technique used to represent categorical variables as binary vectors. This method converts each distinct category into a binary feature: a '1' indicates the presence of that category, while all other related elements are '0'.\n",
    "\n",
    "Occasionally, for a specific class of features, such as \"birthday,\" a node might exhibit all zeros across its categorical values. The most straightforward explanation for this is simply that the information for that particular user was either unavailable or not provided in the dataset.\n",
    "\n",
    "While columns representing the same feature class could be merged into a single column with multiple categorical values (e.g., birthday='6'), which would improve *human readability*, this approach presents drawbacks for Logistic Regression models. These models require *numerical input*, such as binary values. Converting to distinct, non-ordered categories would cause the model to mistakenly interpret a value like '7' as \"greater\" than '0' (e.g., birthday 7 as superior to birthday 0), despite the dataset not specifying any **ordinal relationship between categories**.\n",
    "\n",
    "Consequently, the DataFrame is maintained in its current one-hot encoded format. The primary drawback of this approach is an **increased dimensionality**, but it ensures the data is optimally prepared for logistic regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56870b98",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a695c88",
   "metadata": {},
   "source": [
    "### Graph Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ecb8eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 333 nodes and 2519 edges\n",
      "Average degree: 15.1\n",
      "Max degree: 77\n",
      "Min degree: 1\n",
      "Density: 0.0456\n"
     ]
    }
   ],
   "source": [
    "density = nx.density(G)\n",
    "\n",
    "print(G)\n",
    "print(f'Average degree: {sum(dict(G.degree).values()) / len(G.nodes):.1f}')\n",
    "print(f'Max degree: {max(dict(G.degree).values())}')\n",
    "print(f'Min degree: {min(dict(G.degree).values())}')\n",
    "print(f'Density: {density:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db067c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dbc790b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of connected components: 5\n",
      "Largest Connected Component: Graph with 324 nodes and 2514 edges\n"
     ]
    }
   ],
   "source": [
    "# Connected Components\n",
    "print(\"Number of connected components:\", nx.number_connected_components(G))\n",
    "\n",
    "G_lcc = G.subgraph(max(nx.connected_components(G), key=len)).copy()\n",
    "print(\"Largest Connected Component:\", G_lcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29743c2",
   "metadata": {},
   "source": [
    "This is an interesting result: I initially supposed that in an ego network there would have been a single connected component, while i actually found five. After further investigation i found that in the readme file provided with the dataset is specified that the ego node is removed from the ego graph. This seems to be common in ego networks: by definition the central ego node is always connected to all of its direct friends and there is no need to to explicitly list all its edges.\n",
    "\n",
    "This changes the goal of the prediction task to identifying potential new or missing connections between pairs of the ego's friends who are not currently connected.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95eca242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Local Clustering: 0.5082\n",
      "Transitivity: 0.4259\n"
     ]
    }
   ],
   "source": [
    "# Clustering\n",
    "print(f'Average Local Clustering: {nx.average_clustering(G):.4f}')\n",
    "print(f'Transitivity: {nx.transitivity(G):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee3a88",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b86d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Shortest Path Length in the LCC: 3.75\n",
      "Diameter of LCC: 11\n"
     ]
    }
   ],
   "source": [
    "# Distances\n",
    "print(f'Average Shortest Path Length in the LCC: {nx.average_shortest_path_length(G_lcc):.2f}')\n",
    "print('Diameter of LCC:', nx.diameter(G_lcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae9b14",
   "metadata": {},
   "source": [
    "This two values are probably much higher with the ego node removed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d3d2a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Assortativity of LCC: 0.23\n"
     ]
    }
   ],
   "source": [
    "# Assortativity\n",
    "print(f'Degree Assortativity of LCC: {nx.degree_assortativity_coefficient(G_lcc):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af22de",
   "metadata": {},
   "source": [
    "This suggests that there is a slight tendency for high-degree nodes to connect to other high-degree nodes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b273d4b1",
   "metadata": {},
   "source": [
    "#### Degree Distribution Analysis\n",
    "Looking at the degree distribution, we can make hypotheses on the performance of the Preferential Attachment measure for link prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5639283d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Linear Scale Histogram\n",
    "plot.degree_count_plot(G_lcc, logy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa75ca69",
   "metadata": {},
   "source": [
    "From this plot i can already assume that there isn't a clear power-law distribution (multiple bumps beyond the initial sharp peak) and preferential attachment might not be the dominant generative feature in this particular ego network, without needing to perform the log-log plot to confirm it. \n",
    "\n",
    "I will still consider degree-based features, because could always be relevant as demonstrated in previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b864e",
   "metadata": {},
   "source": [
    "### Node Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa8150be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the feature dataframe with the nodes in the LCC\n",
    "lcc_feat_df = features_df[features_df.index.isin(G_lcc.nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb75f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 324 entries, 1 to 347\n",
      "Columns: 224 entries, birthday;anonymized feature 0 to work;with;id;anonymized feature 205\n",
      "dtypes: int64(224)\n",
      "memory usage: 569.5 KB\n"
     ]
    }
   ],
   "source": [
    "lcc_feat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f63f06c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Top 10 Most Frequent Features --\n",
      "locale;anonymized feature 127                       0.938272\n",
      "education;type;anonymized feature 53                0.675926\n",
      "gender;anonymized feature 78                        0.623457\n",
      "education;type;anonymized feature 55                0.608025\n",
      "education;school;id;anonymized feature 50           0.462963\n",
      "gender;anonymized feature 77                        0.358025\n",
      "education;type;anonymized feature 54                0.228395\n",
      "education;concentration;id;anonymized feature 14    0.228395\n",
      "education;year;id;anonymized feature 65             0.212963\n",
      "languages;id;anonymized feature 92                  0.194444\n",
      "dtype: float64\n",
      "\n",
      "-- Bottom 10 Top Frequent Features --\n",
      "work;end_date;anonymized feature 159       0.006173\n",
      "work;location;id;anonymized feature 175    0.006173\n",
      "work;start_date;anonymized feature 203     0.006173\n",
      "work;position;id;anonymized feature 187    0.006173\n",
      "work;position;id;anonymized feature 190    0.006173\n",
      "work;position;id;anonymized feature 191    0.006173\n",
      "work;with;id;anonymized feature 205        0.006173\n",
      "work;employer;id;anonymized feature 149    0.003086\n",
      "work;employer;id;anonymized feature 146    0.003086\n",
      "work;end_date;anonymized feature 160       0.003086\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feature_frequency = lcc_feat_df.mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"-- Top 10 Most Frequent Features --\")\n",
    "print(feature_frequency.head(10))\n",
    "print(\"\\n-- Bottom 10 Top Frequent Features --\")\n",
    "print(feature_frequency.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3fd897",
   "metadata": {},
   "source": [
    "Some features are extremely common or extremely rare and could not be valuable for link prediction (might not provide a valid indicator or might lack of discriminative power, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76448db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of Number of Active (=1) Features per Node\n",
    "num_active_features_per_node = lcc_feat_df.sum(axis=1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(num_active_features_per_node, bins=30) #type: ignore\n",
    "plt.title('Distribution of Number of Active (=1) Features Per Node')\n",
    "plt.xlabel('Number of Active Features')\n",
    "plt.ylabel('Number of Nodes')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986d694",
   "metadata": {},
   "source": [
    "Most nodes have very sparse feature vectors and few nodes have a rich feature profile (could be hubs).\n",
    "\n",
    "Having the features represented with one-hot encoding it could be useful to group them to make further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46631539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'birthday': 8,\n",
       " 'education;classes;id': 5,\n",
       " 'education;concentration;id': 7,\n",
       " 'education;degree;id': 4,\n",
       " 'education;school;id': 29,\n",
       " 'education;type': 3,\n",
       " 'education;with;id': 1,\n",
       " 'education;year;id': 16,\n",
       " 'first_name': 4,\n",
       " 'gender': 2,\n",
       " 'hometown;id': 11,\n",
       " 'languages;id': 14,\n",
       " 'last_name': 21,\n",
       " 'locale': 3,\n",
       " 'location;id': 12,\n",
       " 'work;employer;id': 20,\n",
       " 'work;end_date': 16,\n",
       " 'work;location;id': 12,\n",
       " 'work;position;id': 13,\n",
       " 'work;start_date': 22,\n",
       " 'work;with;id': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_classes_values = {}\n",
    "\n",
    "for full_feature_name in lcc_feat_df.columns:\n",
    "    parts = full_feature_name.rsplit(';anonymized feature ', 1)\n",
    "\n",
    "    feature_base_name = parts[0].strip()\n",
    "\n",
    "    if feature_base_name not in feature_classes_values:\n",
    "        feature_classes_values[feature_base_name] = 0\n",
    "    feature_classes_values[feature_base_name]+=1\n",
    "\n",
    "print(\"Length: \", len(feature_classes_values))\n",
    "feature_classes_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964f04d",
   "metadata": {},
   "source": [
    "There are basic features like first name, last name and gender but also specialized features like the ones relative to education and work. <br>\n",
    "The first thing that seems a bit off is the number of distinct values for some features, like `first_name` that has only 4. This is probably a result of the anonymization process, maybe through bucketing, but is indeed curious how they managed to fit all the first names into only 4 anonymized buckets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1150fd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Class</th>\n",
       "      <th>No Actives</th>\n",
       "      <th>At Least One Active</th>\n",
       "      <th>More Than One Active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>birthday</td>\n",
       "      <td>229</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>education;classes;id</td>\n",
       "      <td>313</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>education;concentration;id</td>\n",
       "      <td>231</td>\n",
       "      <td>93</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education;degree;id</td>\n",
       "      <td>303</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>education;school;id</td>\n",
       "      <td>111</td>\n",
       "      <td>213</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>education;type</td>\n",
       "      <td>81</td>\n",
       "      <td>243</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>education;with;id</td>\n",
       "      <td>322</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>education;year;id</td>\n",
       "      <td>131</td>\n",
       "      <td>193</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>first_name</td>\n",
       "      <td>314</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gender</td>\n",
       "      <td>6</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hometown;id</td>\n",
       "      <td>278</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>languages;id</td>\n",
       "      <td>243</td>\n",
       "      <td>81</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>last_name</td>\n",
       "      <td>272</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>locale</td>\n",
       "      <td>4</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>location;id</td>\n",
       "      <td>172</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>work;employer;id</td>\n",
       "      <td>242</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>work;end_date</td>\n",
       "      <td>211</td>\n",
       "      <td>113</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>work;location;id</td>\n",
       "      <td>238</td>\n",
       "      <td>86</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>work;position;id</td>\n",
       "      <td>264</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>work;start_date</td>\n",
       "      <td>192</td>\n",
       "      <td>132</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>work;with;id</td>\n",
       "      <td>322</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature Class  No Actives  At Least One Active  \\\n",
       "0                     birthday         229                   95   \n",
       "1         education;classes;id         313                   11   \n",
       "2   education;concentration;id         231                   93   \n",
       "3          education;degree;id         303                   21   \n",
       "4          education;school;id         111                  213   \n",
       "5               education;type          81                  243   \n",
       "6            education;with;id         322                    2   \n",
       "7            education;year;id         131                  193   \n",
       "8                   first_name         314                   10   \n",
       "9                       gender           6                  318   \n",
       "10                 hometown;id         278                   46   \n",
       "11                languages;id         243                   81   \n",
       "12                   last_name         272                   52   \n",
       "13                      locale           4                  320   \n",
       "14                 location;id         172                  152   \n",
       "15            work;employer;id         242                   82   \n",
       "16               work;end_date         211                  113   \n",
       "17            work;location;id         238                   86   \n",
       "18            work;position;id         264                   60   \n",
       "19             work;start_date         192                  132   \n",
       "20                work;with;id         322                    2   \n",
       "\n",
       "    More Than One Active  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      8  \n",
       "3                      4  \n",
       "4                     56  \n",
       "5                    202  \n",
       "6                      0  \n",
       "7                    127  \n",
       "8                      0  \n",
       "9                      0  \n",
       "10                     0  \n",
       "11                    51  \n",
       "12                     0  \n",
       "13                     0  \n",
       "14                     0  \n",
       "15                    32  \n",
       "16                    47  \n",
       "17                    24  \n",
       "18                    12  \n",
       "19                    66  \n",
       "20                     0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_grouped_by_feature_class = {}\n",
    "\n",
    "for column_name in lcc_feat_df.columns:\n",
    "    match = re.search(r';anonymized feature \\d+$', column_name)\n",
    "\n",
    "    if match:\n",
    "        feature_base_name = column_name[:match.start()].strip()\n",
    "\n",
    "    if feature_base_name not in columns_grouped_by_feature_class:\n",
    "        columns_grouped_by_feature_class[feature_base_name] = []\n",
    "    columns_grouped_by_feature_class[feature_base_name].append(column_name)\n",
    "\n",
    "tmp_data = []\n",
    "\n",
    "for feature_class, columns in columns_grouped_by_feature_class.items():\n",
    "    count = lcc_feat_df[columns].sum(axis=1)\n",
    "\n",
    "    no_actives = (count == 0).sum()\n",
    "    at_least_one_active = (count > 0).sum()\n",
    "    more_than_one_active = (count > 1).sum()\n",
    "\n",
    "    tmp_data.append({\n",
    "        'Feature Class': feature_class,\n",
    "        'No Actives': no_actives,\n",
    "        'At Least One Active': at_least_one_active,\n",
    "        'More Than One Active': more_than_one_active\n",
    "    })\n",
    "\n",
    "feature_classes_actives = pd.DataFrame(tmp_data)\n",
    "feature_classes_actives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab21224",
   "metadata": {},
   "source": [
    "This table gives other valuable insights on what types of data this dataset had originally:\n",
    "- Some feature classes are **exclusive** (birthday, first name, gender, ...) but others are not (languages, education type, work location, ...).\n",
    "- Some feature classes have no active values (**no data**) for many nodes, confirming what already emerged while creating the dataframe.\n",
    "\n",
    "Also, the last observation done on the first name values, could actually be *wrong*: the table showed that 314 out of 324 nodes have no data for the first name feature, potentially meaning that no bucketing has been made, and, given the high number of \"**No Actives**\" across all feature classes, this really seems to be the case of **data missingness**. *Why?*\n",
    "\n",
    "Anyway, this table combined with the top and bottom most frequent features gives some strong indicators of which feature could be the most effective to select."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4815812d",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dc5b2f",
   "metadata": {},
   "source": [
    "### Topological Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b5d8f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_topological_feature_vector(pairs, G, features=['cn', 'jc', 'aa', 'pa', 'ra']):\n",
    "    feature_data = {}\n",
    "\n",
    "    if 'cn' in features:\n",
    "        feature_data['cn'] = [len(list(nx.common_neighbors(G, u, v))) for u, v in pairs]\n",
    "\n",
    "    if 'jc' in features:\n",
    "        feature_data['jc'] = [coeff for _, _, coeff in nx.jaccard_coefficient(G, pairs)]\n",
    "\n",
    "    if 'aa' in features:\n",
    "        aa_scores = []\n",
    "        for u_node, v_node in pairs:\n",
    "            try:\n",
    "                _, _, score = list(nx.adamic_adar_index(G, [(u_node, v_node)]))[0]\n",
    "                aa_scores.append(score)\n",
    "            except (ZeroDivisionError, StopIteration):\n",
    "                aa_scores.append(0.0)\n",
    "        feature_data['aa'] = aa_scores\n",
    "\n",
    "    if 'pa' in features:\n",
    "        feature_data['pa'] = [coeff for _, _, coeff in nx.preferential_attachment(G, pairs)]\n",
    "\n",
    "    if 'ra' in features:\n",
    "        feature_data['ra'] = [coeff for _, _, coeff in nx.resource_allocation_index(G, pairs)]\n",
    "\n",
    "    # Combine feature\n",
    "    feature_vectors = []\n",
    "    for i in range(len(pairs)):\n",
    "        vector = [feature_data[feat][i] for feat in features]\n",
    "        feature_vectors.append(vector)\n",
    "\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf8b5f",
   "metadata": {},
   "source": [
    "The initial baseline will be formed by the 5 topological features already used in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e08f8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "topological_features = ['cn', 'jc', 'aa', 'pa', 'ra']\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train, X_test, y_train, y_test = splits.create_train_test_split(\n",
    "    G_lcc,\n",
    "    lambda pairs, G_train_graph: build_topological_feature_vector(pairs, G_train_graph, topological_features),\n",
    "    lambda: ns.common_neighbors_hard_negative_sampling(G_lcc)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a9df5a",
   "metadata": {},
   "source": [
    "---\n",
    "Feature Scaling is a critical step for Logistic Regression. The weight learned by the model are directly influenced by the scale of the features, this makes the raw coefficients incomparable. The StandardScaler transform each feature to have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb74080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train) # type: ignore\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511a734a",
   "metadata": {},
   "source": [
    "---\n",
    "Now two Logistic Regression models will be trained to compare two different types of regularization: L2 and L1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f18d3ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "X_train_scaled, X_test_scaled = scale_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef8fe171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L2 Regularization (Ridge)\n",
      "Features:      ['cn', 'jc', 'aa', 'pa', 'ra']\n",
      "Coefficients:  [-0.66862857 -0.44571748  0.11018249 -0.19465749  1.89131588]\n",
      "AUC-PR Score: 0.7571\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression with L2 Regularization\n",
    "lr_l2 = LogisticRegression(penalty='l2', random_state=42, max_iter=1000)\n",
    "lr_l2.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr_l2 = lr_l2.predict_proba(X_test_scaled)[:, 1] # type: ignore\n",
    "coeffs_lr_l2 = lr_l2.coef_[0]\n",
    "\n",
    "print('Logistic Regression with L2 Regularization (Ridge)')\n",
    "print('Features:     ', topological_features)\n",
    "print('Coefficients: ', coeffs_lr_l2)\n",
    "print(f'AUC-PR Score: {average_precision_score(y_test, y_pred_lr_l2):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f50f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L1 Regularization (Lasso)\n",
      "Features:      ['cn', 'jc', 'aa', 'pa', 'ra']\n",
      "Coefficients:  [-0.58162816 -0.32394267  0.         -0.1197314   1.73955328]\n",
      "AUC-PR Score: 0.7593\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression with L1 Regularization\n",
    "lr_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.1, random_state=42, max_iter=1000)\n",
    "lr_l1.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr_l1 = lr_l1.predict_proba(X_test_scaled)[:, 1] # type: ignore\n",
    "coeffs_lr_l1 = lr_l1.coef_[0]\n",
    "\n",
    "print('Logistic Regression with L1 Regularization (Lasso)')\n",
    "print('Features:     ', topological_features)\n",
    "print('Coefficients: ', coeffs_lr_l1)\n",
    "print(f'AUC-PR Score: {average_precision_score(y_test, y_pred_lr_l1):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6d8cd",
   "metadata": {},
   "source": [
    "The results from the two models reveals that:\n",
    "- L2 (Ridge): This model achieved an AUC-PR of ~0.76. It kept all five features but produced counter-intuitive negative coefficients for `cn`, `jc`, and `pa`. This is a symptom of **multicollinearity**, where the model is confused by the redundant information in the features and cannot assign stable, meaningful weights.\n",
    "- L1 (Lasso): This model achieved a similar score. However, it has set the coefficient for `aa` to exactly *0.0*. This happens because, given the other features, `aa` is the most redundant and can be removed without harming performance.\n",
    "\n",
    "This comparison strongly suggests that our feature set is too complex and redundant for a linear model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d6873a",
   "metadata": {},
   "source": [
    "To confirm the obtained results and the diagnosis made, we can try to train a Random Forest and see the feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eab6a8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Features:      ['cn', 'jc', 'aa', 'pa', 'ra']\n",
      "Importances:   [0.06605142 0.18098669 0.22225856 0.22820369 0.30249964]\n",
      "AUC-PR Score: 0.8116\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "auc_pr_rf = average_precision_score(y_test, y_pred_rf)\n",
    "\n",
    "print('Random Forest')\n",
    "print('Features:     ', topological_features)\n",
    "print('Importances:  ', rf.feature_importances_)\n",
    "print(f'AUC-PR Score: {average_precision_score(y_test, y_pred_rf):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fd46c",
   "metadata": {},
   "source": [
    "The Random Forest model results support the findings:\n",
    "- The AUC-PR score is higher than Logistic Regression models proving the features are valuable when used by a suitable model.\n",
    "- The importances clearly show that Resource Allocation (`ra`) is the single most powerful predictor.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd252df5",
   "metadata": {},
   "source": [
    "Given that in all trained models `ra` has resulted the best predictor and is also the only one that has a positive coefficient with L1 regularization, we can opt to select this single feature for the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66a9695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "topological_features = ['ra']\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train, X_test, y_train, y_test = splits.create_train_test_split(\n",
    "    G_lcc,\n",
    "    lambda pairs, G_train_graph: build_topological_feature_vector(pairs, G_train_graph, topological_features),\n",
    "    lambda: ns.common_neighbors_hard_negative_sampling(G_lcc)\n",
    ")\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled, X_test_scaled = scale_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "915a8aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L2 Regularization (Ridge)\n",
      "Features:      ['ra']\n",
      "Coefficients:  [0.95251243]\n",
      "AUC-PR Score: 0.7623\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "lr_l2 = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_l2.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr_l2 = lr_l2.predict_proba(X_test_scaled)[:, 1] # type: ignore\n",
    "coeffs_lr_l2 = lr_l2.coef_[0]\n",
    "\n",
    "print('Logistic Regression with L2 Regularization (Ridge)')\n",
    "print('Features:     ', topological_features)\n",
    "print('Coefficients: ', coeffs_lr_l2)\n",
    "print(f'AUC-PR Score: {average_precision_score(y_test, y_pred_lr_l2):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595409a",
   "metadata": {},
   "source": [
    "As expected the single-feature Linear Regression model obtained a slightly higher score than the previous models, so, as topological feature, only `ra` is selected.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd047134",
   "metadata": {},
   "source": [
    "### Node Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bf600",
   "metadata": {},
   "source": [
    "With 224 features and only 324 nodes, the model has a high risk of overfitting instead of learning true patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9709a0",
   "metadata": {},
   "source": [
    "We can start by removing features classes that are present in very few nodes, because are unlikely to generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f07bed32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns:  11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['education;classes;id;anonymized feature 8',\n",
       " 'education;classes;id;anonymized feature 9',\n",
       " 'education;classes;id;anonymized feature 10',\n",
       " 'education;classes;id;anonymized feature 11',\n",
       " 'education;classes;id;anonymized feature 12',\n",
       " 'education;with;id;anonymized feature 56',\n",
       " 'first_name;anonymized feature 73',\n",
       " 'first_name;anonymized feature 74',\n",
       " 'first_name;anonymized feature 75',\n",
       " 'first_name;anonymized feature 76',\n",
       " 'work;with;id;anonymized feature 205']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heuristic_threshold = 0.95 # Searching for feature classes that have this percentage of 'No Actives' values (over the total entries)\n",
    "\n",
    "tmp = feature_classes_actives[feature_classes_actives['No Actives']>(lcc_feat_df.shape[0] * heuristic_threshold)]\n",
    "features_classes_to_remove = tmp['Feature Class']\n",
    "\n",
    "columns_to_remove = [col for col in lcc_feat_df.columns if any(col.startswith(prefix) for prefix in features_classes_to_remove)]\n",
    "\n",
    "selected_features_df = lcc_feat_df.drop(columns=columns_to_remove)\n",
    "\n",
    "print('Removed columns: ', len(columns_to_remove))\n",
    "columns_to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b24fec",
   "metadata": {},
   "source": [
    "Some columns have been removed: we can be almost certain that those feature will not improve the model prediction and would probably have added some noise.\n",
    "\n",
    "---\n",
    "\n",
    "To enable our model to predict a link between a pair of nodes, we must convert their individual node feature vectors into a single combined feature vector. After some testing the choice of the combination technique falls on **L1 Distance (Manhattan Distance)** that calculates a vector where each element is 1 if the nodes disagree on a specific attribute and 0 if they agree (**homophily**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f44c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_combined_feature_vector(pairs, G, feature_df, topological_features=[]):\n",
    "    feature_vectors = []\n",
    "\n",
    "    for u, v in pairs:\n",
    "        topological_features_vector = build_topological_feature_vector([(u, v)], G, features=topological_features)[0]\n",
    "\n",
    "        # L1 Distance (Manhattan Distance)\n",
    "        features_u = feature_df.loc[u]\n",
    "        features_v = feature_df.loc[v]\n",
    "        node_pair_vector = np.abs(features_u - features_v).tolist()\n",
    "\n",
    "        # Combine Topological and Node features vectors\n",
    "        combined_vector = topological_features_vector + node_pair_vector\n",
    "        feature_vectors.append(combined_vector)\n",
    "\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f443e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing sets\n",
    "X_train, X_test, y_train, y_test = splits.create_train_test_split(\n",
    "    G_lcc,\n",
    "    lambda pairs, G_train_graph: build_combined_feature_vector(pairs, G_train_graph, selected_features_df, topological_features=['ra']),\n",
    "    lambda: ns.common_neighbors_hard_negative_sampling(G_lcc)\n",
    ")\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled, X_test_scaled = scale_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91243099",
   "metadata": {},
   "source": [
    "The features can be selected more by using L1 Regularization: the features that gets coefficients =0 are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11be4766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with L1 Regularization\n",
      "AUC-PR Score:  0.7865\n",
      "Features sorted by absolute value of coefficient (Total features: 140): \n",
      "                                       feature  coefficient\n",
      "0                                           ra     0.884041\n",
      "199     work;start_date;anonymized feature 162     0.252371\n",
      "149    work;employer;id;anonymized feature 155    -0.197752\n",
      "194     work;start_date;anonymized feature 195     0.166460\n",
      "170    work;location;id;anonymized feature 132    -0.158082\n",
      "68                gender;anonymized feature 77    -0.133408\n",
      "182    work;position;id;anonymized feature 184    -0.122653\n",
      "166       work;end_date;anonymized feature 172    -0.121451\n",
      "27   education;school;id;anonymized feature 31     0.113245\n",
      "126         location;id;anonymized feature 135    -0.106955\n",
      "2                birthday;anonymized feature 1     0.101330\n",
      "31   education;school;id;anonymized feature 35     0.100765\n",
      "42   education;school;id;anonymized feature 46    -0.099978\n",
      "32   education;school;id;anonymized feature 36     0.094528\n",
      "62     education;year;id;anonymized feature 67    -0.094175\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression with L1 Regularization\n",
    "l1_selector = LogisticRegression(penalty='l1', solver='liblinear', C=0.1, random_state=42, max_iter=1000)\n",
    "l1_selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the features with non-zero coefficients\n",
    "l1_coeffs = l1_selector.coef_[0]\n",
    "feature_names = topological_features + selected_features_df.columns.tolist()\n",
    "important_features_l1 = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': l1_coeffs\n",
    "}).query('coefficient != 0').sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "y_pred_l1_selector = l1_selector.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print('Logistic Regression with L1 Regularization')\n",
    "print(f'AUC-PR Score:  {average_precision_score(y_test, y_pred_l1_selector):.4f}')\n",
    "print(f'Features sorted by absolute value of coefficient (Total features: {important_features_l1.shape[0]}): ')\n",
    "print(important_features_l1.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f69275",
   "metadata": {},
   "source": [
    "From this model we can note that:\n",
    "- The AUC-PR score has improved.\n",
    "- Another good chunk of features can be removed as they have got a coefficient equal to zero. \n",
    "- Only few feature have a significant weight, with `ra` being dominant.\n",
    "\n",
    "---\n",
    "We can again compare the results with a Random Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84051bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "AUC-PR Score: 0.7570\n",
      "Features sorted by absolute value of coefficient: \n",
      "                                              feature  importance\n",
      "0                                                  ra    0.273225\n",
      "68                       gender;anonymized feature 77    0.019289\n",
      "69                       gender;anonymized feature 78    0.018368\n",
      "129                location;id;anonymized feature 137    0.017214\n",
      "123                location;id;anonymized feature 132    0.013802\n",
      "54            education;year;id;anonymized feature 59    0.013015\n",
      "49               education;type;anonymized feature 53    0.012948\n",
      "46          education;school;id;anonymized feature 50    0.012841\n",
      "83                 languages;id;anonymized feature 92    0.012671\n",
      "51               education;type;anonymized feature 55    0.011934\n",
      "10   education;concentration;id;anonymized feature 14    0.011886\n",
      "8                       birthday;anonymized feature 7    0.011744\n",
      "103                  last_name;anonymized feature 112    0.011587\n",
      "136           work;employer;id;anonymized feature 144    0.010095\n",
      "60            education;year;id;anonymized feature 65    0.009937\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the features importance\n",
    "important_features_rf = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "y_pred_rf = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print('Random Forest')\n",
    "print(f'AUC-PR Score: {average_precision_score(y_test, y_pred_rf):.4f}')\n",
    "print('Features sorted by absolute value of coefficient: ')\n",
    "print(important_features_rf.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae18f9",
   "metadata": {},
   "source": [
    "The Random Forest feature importances were consistent with the Logistic Regression coefficients, by highlighting the dominance of `ra` as predictive feature.\n",
    "\n",
    "However, while the Logistic Regression improved its score, the Random Forest lost some points and got a lower score than Logistic Regression. This could have caused by the Random Forest feature subsampling: selecting a random set of feature to create each decision tree, while having only few features that are strong predictors resulted in many trees built with only weak and noisy features, and their poor results averaged in the final result, degrading the overall score.\n",
    "\n",
    "---\n",
    "The next step is trying to remove the features that received a 0 coefficient form L1 Regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6203d0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 140 features with absolute coefficient > 0.0\n"
     ]
    }
   ],
   "source": [
    "# Threshold variable for testing different values\n",
    "coefficient_threshold = 0.0\n",
    "\n",
    "# Select features with absolute coefficient > coefficient_threshold\n",
    "selected_features = important_features_l1[\n",
    "    abs(important_features_l1['coefficient']) > coefficient_threshold\n",
    "]['feature'].tolist()\n",
    "\n",
    "# Split Topological features from Node features\n",
    "selected_topological_features = [f for f in selected_features if f in topological_features]\n",
    "selected_node_features = [f for f in selected_features if f in selected_features_df.columns]\n",
    "selected_node_features_df = selected_features_df[selected_node_features]\n",
    "\n",
    "print(f'Selected {len(selected_features)} features with absolute coefficient > {coefficient_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "732e0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new training and testing sets using only the champion features\n",
    "X_train, X_test, y_train, y_test = splits.create_train_test_split(\n",
    "    G_lcc,\n",
    "    lambda pairs, G_train_graph: build_combined_feature_vector(\n",
    "        pairs,\n",
    "        G_train_graph,\n",
    "        selected_node_features_df,\n",
    "        topological_features=selected_topological_features\n",
    "    ),\n",
    "    lambda: ns.common_neighbors_hard_negative_sampling(G_lcc)\n",
    ")\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled, X_test_scaled = scale_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7917f18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "AUC-PR Score: 0.8070\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_final = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "auc_pr_final = average_precision_score(y_test, y_pred_final)\n",
    "\n",
    "print('Logistic Regression')\n",
    "print(f'AUC-PR Score: {auc_pr_final:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf34d25",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737b2a1",
   "metadata": {},
   "source": [
    "The analysis made in this notebook is a form of **ablation study**, here's all results obtained:\n",
    "\n",
    "| **Model Type** | **Feature Set** | **AUC-PR Score** | **Notes** |\n",
    "|----------------|-----------------|------------------|-----------| \n",
    "| **Logistic Regression (L2)** | All 5 topological features | 0.7571 | The baseline to test the difference between L1/L2 Regularization and choose the best topological features |\n",
    "| **Logistic Regression (L1)** | All 5 topological features | 0.7593 | Confirmed multicollinearity by setting the `aa` coefficient to zero. |\n",
    "| **Random Forest** | All 5 topological features | 0.8116 | *Highest overall score.* Proved the features are valuable when used by a model robust to multicollinearity. |\n",
    "| **Logistic Regression (L2)** | `ra` (L1-selected) | 0.7623 | Showed that a single topological feature could match the performance of all five, confirming feature redundancy. |\n",
    "| **Logistic Regression (L1)**  | `ra` + 224 node features (heuristic-selected) | 0.7865 | The addition of node features provided a performance boost over topology alone. |\n",
    "| **Random Forest** | `ra` + 224 node features (heuristic-selected) | 0.7570 | Performed worse than its LR counterpart, suggesting the node features added more noise than useful signal for the ensemble. |\n",
    "| **Logistic Regression (L2)**  | `ra` + 140 node features (L1-selected)| 0.8070 | *Best LR Score.* Removing noisy features with L1 allowed the model to achieve its peak performance, almost matching the best RF score. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fcde5f",
   "metadata": {},
   "source": [
    "The first models highlighted how strong topological features are, especially when combined with a model robust to multicollinearity. However, the addition of node features helped to narrow the gap between a linear (LR) and a non-linear classifier (RF), by adding small, but still, valuable information. At the same time can also be noted that Random Forest lowered it's score, resulted being even lower than Logistic Regression with the combination of topological and node features (as already explained).\n",
    "\n",
    "The most significant performance gains came from a multi-stage feature selection process:\n",
    "1. Started with 224 node features\n",
    "2. Applied a simple heuristic to remove sparse features.\n",
    "3. Used multiple times L1 Regularization to automatically identify the ~140 topological and node features with the most predictive power.\n",
    "\n",
    "This analysis demonstrated that the choice of the model is as important and impactful as the feature engineering process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

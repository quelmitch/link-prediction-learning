{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1867763",
   "metadata": {},
   "source": [
    "# Gowalla - Modelling\n",
    "After looking at the data in the EDA, it's time to build our prediction model. The main goal is to predict if two users will be friends based on their behavior and their place in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54098aa9",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96c9d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from haversine import haversine_vector\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e88123",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "pd.set_option('display.float_format', '{:.10f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8672b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_path = 'data/Gowalla_edges.txt'\n",
    "\n",
    "# Data loading\n",
    "G = nx.read_edgelist(edges_path, nodetype=int)\n",
    "checkins_df = pd.read_parquet('data/EDA_output/checkins.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49632a22",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef635e1c",
   "metadata": {},
   "source": [
    "Initially, a simple random 80/20 split of the edges was considered for creating the training and test sets. However, this approach was identified as methodologically flawed for a temporal dataset. A random split could create a scenario where the model is trained on check-in features from 2010 to predict a link that was held out for the test set, even if that link represents a friendship from 2009. This constitutes a form of data leakage, where information from the future is used to predict the past, leading to an overly optimistic and unrealistic evaluation of the model's performance.\"\n",
    "\n",
    "To avoid this temporal leakage and address the limitations of the data, we reframe the prediction task. Given the absence of friendship formation timestamps that makes true temporal prediction impossible, we *shift from predicting link formation to predicting link existence within the final network snapshot*.\n",
    "\n",
    "> Can we use a user's early activity to effectively distinguish between user pairs who are friends and those who are not in the final, complete social network?\n",
    "\n",
    "In this new objective we accept **structural leakage** by using the final graph for embeddings, but we explicitly define the task around this by predicting the *final state*, not the *formation*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5897528",
   "metadata": {},
   "source": [
    "### Feature Dataset Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7fcbad",
   "metadata": {},
   "source": [
    "We proceed to make the 80/20 split of the check-ins. We have two alternative:\n",
    "- Split by volume of check-ins (e.g. train set will have 80% of check-ins)\n",
    "- Split by time passed (e.g train set will have check-ins that appears in the first 80% of time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f585fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check-ins cutoff at:  2010-06-20 00:33:12.400000+00:00\n",
      "Train set size: 2939173 - Corresponding percentage of volume: 45.6\n",
      "Test set size:  3503690 - Corresponding percentage of volume: 54.4\n"
     ]
    }
   ],
   "source": [
    "# Split the check-ins dataframe by time\n",
    "min_ts = checkins_df['check-in_datetime'].min()\n",
    "max_ts = checkins_df['check-in_datetime'].max()\n",
    "\n",
    "time_diff = max_ts - min_ts\n",
    "\n",
    "time_cutoff = min_ts + pd.to_timedelta(0.8 * time_diff)\n",
    "\n",
    "t_train_df = checkins_df[checkins_df['check-in_datetime'] < time_cutoff]\n",
    "t_test_df = checkins_df[checkins_df['check-in_datetime'] >= time_cutoff]\n",
    "\n",
    "print(\"Check-ins cutoff at: \", time_cutoff)\n",
    "print(f\"Train set size: {len(t_train_df)} - Corresponding percentage of volume: {len(t_train_df)/len(checkins_df)*100:.1f}\")\n",
    "print(f\"Test set size:  {len(t_test_df)} - Corresponding percentage of volume: {len(t_test_df)/len(checkins_df)*100:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f1e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check-ins cutoff at:  2010-09-14 14:24:41+00:00\n",
      "Train set size: 5154291 - Corresponding percentage of time: 93.8\n",
      "Test set size:  1288572 - Corresponding percentage of time: 6.2\n"
     ]
    }
   ],
   "source": [
    "# Split the check-ins dataframe by volume\n",
    "volume_cutoff = math.ceil(len(checkins_df) * 0.80)\n",
    "\n",
    "checkins_df = checkins_df.sort_values(by=['check-in_datetime'])\n",
    "\n",
    "v_train_df = checkins_df.iloc[:volume_cutoff]\n",
    "v_test_df = checkins_df.iloc[volume_cutoff:]\n",
    "\n",
    "volume_cutoff_ts = checkins_df.iloc[volume_cutoff]['check-in_datetime']\n",
    "\n",
    "print(\"Check-ins cutoff at: \", volume_cutoff_ts)\n",
    "print(f\"Train set size: {len(v_train_df)} - Corresponding percentage of time: {((volume_cutoff_ts - min_ts) / time_diff) * 100:.1f}\")\n",
    "print(f\"Test set size:  {len(v_test_df)} - Corresponding percentage of time: {((max_ts - volume_cutoff_ts) / time_diff) * 100:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddd4050",
   "metadata": {},
   "source": [
    "Either way we obtain an overall imbalanced split, and either options have pros and cons:\n",
    "- Option \"Time\": This is the most honest representation of a real-world temporal prediction task, but the features built from this sparser data might be weak.\n",
    "- Option \"Volume\": The features built will be much stronger and the model will surely perform better, but the separation between past and future is tiny.\n",
    "\n",
    "As the goal of the notebook is learning, we proceed with the time-based split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e13a1d9",
   "metadata": {},
   "source": [
    "### Negative Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ece56",
   "metadata": {},
   "source": [
    "To create a balanced dataset we take an equal number of positive and negative samples. To make the training set challenging, we use a mixed strategy:\n",
    "- 70% of negative samples are \"hard\" negatives generated with random walks with a path distance of 2.\n",
    "- 20% are \"medium\" negatives generated with random walks with a path distance of 4, representing users who are further apart but still connected.\n",
    "- 10% are \"easy\" random negatives, to ensure the model learns the global structure of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d860a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Sampling Generation Functions\n",
    "def _random_walk_hard_negative(graph, count, walk_distance=2, max_attempts=100):\n",
    "    \"\"\"Generates a batch of hard negative samples.\"\"\"\n",
    "    if walk_distance < 1:\n",
    "        raise ValueError(\"walk_distance must be >= 1\")\n",
    "\n",
    "    edges = list(graph.edges())\n",
    "    if not edges:\n",
    "        return []\n",
    "\n",
    "    generated_samples = []\n",
    "    for _ in range(count):\n",
    "        for _ in range(max_attempts):\n",
    "            u, current_node = random.choice(edges)\n",
    "\n",
    "            # Make hops\n",
    "            for _ in range(walk_distance - 1):\n",
    "                neighbors = list(graph.neighbors(current_node))\n",
    "                if not neighbors:\n",
    "                    current_node = None\n",
    "                    break\n",
    "                current_node = random.choice(neighbors)\n",
    "\n",
    "            if current_node is None:\n",
    "                continue\n",
    "\n",
    "            v = current_node\n",
    "\n",
    "            # Validate edge and add to the batch\n",
    "            if v != u and not graph.has_edge(u, v):\n",
    "                generated_samples.append((u, v))\n",
    "                break\n",
    "\n",
    "    return generated_samples\n",
    "\n",
    "def _random_negative_sampling(graph, count, max_attempts=100):\n",
    "    \"\"\"Generates a batch of random negative samples.\"\"\"\n",
    "    nodes = list(graph.nodes())\n",
    "    if len(nodes) < 2:\n",
    "        return []\n",
    "\n",
    "    generated_samples = []\n",
    "    for _ in range(count):\n",
    "        for _ in range(max_attempts):\n",
    "            u, v = random.sample(nodes, 2)\n",
    "            if not graph.has_edge(u, v):\n",
    "                generated_samples.append((u, v))\n",
    "                break\n",
    "\n",
    "    return generated_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c46f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Negative Sampling Function to combine different methods\n",
    "def generate_negative_samples_set(\n",
    "    graph,\n",
    "    sampling_functions,\n",
    "    sampling_weights,\n",
    "    ratio=1.0,\n",
    "    seed=None\n",
    "):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    if len(sampling_functions) != len(sampling_weights):\n",
    "        raise ValueError(\"sampling_functions and sampling_weights must be of the same length\")\n",
    "\n",
    "    total_neg_samples = int(len(graph.edges) * ratio)\n",
    "\n",
    "    weights = np.array(sampling_weights, dtype=float)\n",
    "    weights /= weights.sum()\n",
    "    samples_for_each_function = np.random.multinomial(total_neg_samples, weights)\n",
    "\n",
    "    negative_samples = set()\n",
    "\n",
    "    for func, count in zip(sampling_functions, samples_for_each_function):\n",
    "        if count == 0:\n",
    "            continue\n",
    "\n",
    "        new_samples = func(graph, count)\n",
    "        negative_samples.update(new_samples)\n",
    "\n",
    "    return negative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed9d1a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 973408 (102.43%) negative samples.\n"
     ]
    }
   ],
   "source": [
    "# Generate Negative Samples\n",
    "positive_samples = list(G.edges)\n",
    "\n",
    "sampling_functions = [\n",
    "    lambda g, c: _random_negative_sampling(g, c),\n",
    "    lambda g, c: _random_walk_hard_negative(g, c, walk_distance=4),\n",
    "    lambda g, c: _random_walk_hard_negative(g, c, walk_distance=2)\n",
    "]\n",
    "\n",
    "sampling_weights = [0.1, 0.2, 0.7]\n",
    "\n",
    "negative_samples = generate_negative_samples_set(\n",
    "    graph=G,\n",
    "    sampling_functions=sampling_functions,\n",
    "    sampling_weights=sampling_weights,\n",
    "    ratio=1.1, # Allow to compensate duplicates\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(negative_samples)} ({len(negative_samples)/len(positive_samples)*100:.2f}%) negative samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04954f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate the exceeding part\n",
    "negative_samples = random.sample(list(negative_samples), len(positive_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c2c510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and create labels\n",
    "combined_samples = positive_samples + negative_samples\n",
    "samples_labels = [1] * len(positive_samples) + [0] * len(negative_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fda52e",
   "metadata": {},
   "source": [
    "### Node Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbf3f9d",
   "metadata": {},
   "source": [
    "The goal of **Node Embedding** is to learn a *dense vector representation* for each user that captures their neighborhood and role in the network. This approach allows the model to automatically learn features from the graph topology, serving as a powerful alternative to manual feature engineering with standard measures (e.g., Common Neighbors).\n",
    "\n",
    "We chose the **Node2Vec** algorithm for this task. An initial test with a standard Python implementation of Node2Vec proved to be extremely slow. The first phase of the algorithm, *\"computing transition probabilities\"* was single-threaded and was projected to take several hours. A Stack Overflow discussion<sup>[[1][1]]</sup> highlighted this common bottleneck and pointed towards more performant, specialized libraries.\n",
    "\n",
    "[1]: https://stackoverflow.com/questions/60276191/is-there-any-way-to-make-node2vec-faster\n",
    "\n",
    "Based on this research, we switched to **GRAPE**<sup>[[2][2]]</sup>, a fast graph processing and embedding library. GRAPE is written in *Rust* and *Python*, developed primarily at the University of Milan, and is designed for speed and scalability on massive graphs. It parallelizes the entire Node2Vec process, including the pre-computation step, which dramatically reduces the training time.  \n",
    "While the library's documentation was found to be in a raw state, we were able to successfully implement it for our purposes.\n",
    "\n",
    "[2]: https://github.com/AnacletoLAB/grape\n",
    "\n",
    "To make our workflow efficient and reproducible, we performed this computationally expensive step in a separate script (`train_embeddings.py`) and saved the resulting embeddings to a file. The model was configured with a neutral baseline set of hyperparameters:\n",
    "- `embedding_size` (dimensions): 128\n",
    "- `walk_length` (length of each walk): 80\n",
    "- `iterations` (number of walks per node): 10\n",
    "- `return_weight` ($p = 1 / \\text{return\\_weight}$): 1.0\n",
    "- `explore_weight` ($q = 1 / \\text{explore\\_weight}$): 1.0\n",
    "\n",
    "In the Node2Vec framework `return_weight` and `explore_weight` set to `1.0` corresponds to the parameters `p` and `q`, which removes any search bias and makes the algorithm equivalent to the **DeepWalk** algorithm.\n",
    "\n",
    "The training process, which ran over *30 epochs*, required *35 minutes* to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22834935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Embeddings\n",
    "embedding_path = \"embeddings/gowalla_node2vec_embeddings.parquet\"\n",
    "embedding_df = pd.read_parquet(embedding_path)\n",
    "embedding_df.index = embedding_df.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d817e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.0288829803</td>\n",
       "      <td>-2.8776702881</td>\n",
       "      <td>5.0435833931</td>\n",
       "      <td>-0.2821128666</td>\n",
       "      <td>9.0597715378</td>\n",
       "      <td>3.4204881191</td>\n",
       "      <td>-2.2218639851</td>\n",
       "      <td>-0.9368617535</td>\n",
       "      <td>4.6807227135</td>\n",
       "      <td>0.0228122752</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3902884722</td>\n",
       "      <td>-2.5164117813</td>\n",
       "      <td>6.0603146553</td>\n",
       "      <td>-0.6544523239</td>\n",
       "      <td>-0.8754109144</td>\n",
       "      <td>-1.3680120707</td>\n",
       "      <td>0.5099500418</td>\n",
       "      <td>-1.8036836386</td>\n",
       "      <td>4.5414137840</td>\n",
       "      <td>0.6198633909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-243.1561737061</td>\n",
       "      <td>-22.4067783356</td>\n",
       "      <td>8.4212675095</td>\n",
       "      <td>150.5575103760</td>\n",
       "      <td>-96.7137527466</td>\n",
       "      <td>138.8414306641</td>\n",
       "      <td>-76.1784362793</td>\n",
       "      <td>-37.1504478455</td>\n",
       "      <td>77.4786834717</td>\n",
       "      <td>102.9104461670</td>\n",
       "      <td>...</td>\n",
       "      <td>106.6632690430</td>\n",
       "      <td>32.4698562622</td>\n",
       "      <td>66.7706451416</td>\n",
       "      <td>84.0036621094</td>\n",
       "      <td>107.8564758301</td>\n",
       "      <td>-17.8615455627</td>\n",
       "      <td>-122.0732040405</td>\n",
       "      <td>-141.7993011475</td>\n",
       "      <td>8.2321844101</td>\n",
       "      <td>-47.7921752930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-46.8961753845</td>\n",
       "      <td>-40.1260604858</td>\n",
       "      <td>116.8913192749</td>\n",
       "      <td>-351.3453369141</td>\n",
       "      <td>86.8657608032</td>\n",
       "      <td>-99.9413833618</td>\n",
       "      <td>-94.3557434082</td>\n",
       "      <td>-35.7667655945</td>\n",
       "      <td>-103.2975463867</td>\n",
       "      <td>-206.5962371826</td>\n",
       "      <td>...</td>\n",
       "      <td>174.2192535400</td>\n",
       "      <td>207.1479492188</td>\n",
       "      <td>-160.1919097900</td>\n",
       "      <td>-72.0796051025</td>\n",
       "      <td>231.8607177734</td>\n",
       "      <td>160.5847473145</td>\n",
       "      <td>51.1832656860</td>\n",
       "      <td>3.2517094612</td>\n",
       "      <td>-20.8090553284</td>\n",
       "      <td>-19.6302394867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-24.8522109985</td>\n",
       "      <td>144.9117584229</td>\n",
       "      <td>-16.6605110168</td>\n",
       "      <td>143.6829071045</td>\n",
       "      <td>-99.1568908691</td>\n",
       "      <td>-38.8158988953</td>\n",
       "      <td>-70.0380783081</td>\n",
       "      <td>-80.8727645874</td>\n",
       "      <td>-86.2410125732</td>\n",
       "      <td>5.9249396324</td>\n",
       "      <td>...</td>\n",
       "      <td>265.2242736816</td>\n",
       "      <td>98.8958892822</td>\n",
       "      <td>248.7752227783</td>\n",
       "      <td>395.5150756836</td>\n",
       "      <td>-30.9516849518</td>\n",
       "      <td>-219.1926727295</td>\n",
       "      <td>-90.7720031738</td>\n",
       "      <td>110.5933151245</td>\n",
       "      <td>-107.1297378540</td>\n",
       "      <td>-313.3342895508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.9005260468</td>\n",
       "      <td>0.7149634361</td>\n",
       "      <td>-1.7045143843</td>\n",
       "      <td>1.3454636335</td>\n",
       "      <td>-1.1457815170</td>\n",
       "      <td>-2.3453042507</td>\n",
       "      <td>-0.4327180088</td>\n",
       "      <td>0.9685511589</td>\n",
       "      <td>1.2786015272</td>\n",
       "      <td>-2.0608532429</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.8692209721</td>\n",
       "      <td>1.3978652954</td>\n",
       "      <td>0.8398435712</td>\n",
       "      <td>-1.8602241278</td>\n",
       "      <td>2.5099594593</td>\n",
       "      <td>-1.8832107782</td>\n",
       "      <td>2.1124527454</td>\n",
       "      <td>1.3380315304</td>\n",
       "      <td>-2.2021000385</td>\n",
       "      <td>0.2801496387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0              1              2               3    \\\n",
       "0   -4.0288829803  -2.8776702881   5.0435833931   -0.2821128666   \n",
       "1 -243.1561737061 -22.4067783356   8.4212675095  150.5575103760   \n",
       "2  -46.8961753845 -40.1260604858 116.8913192749 -351.3453369141   \n",
       "3  -24.8522109985 144.9117584229 -16.6605110168  143.6829071045   \n",
       "4   -1.9005260468   0.7149634361  -1.7045143843    1.3454636335   \n",
       "\n",
       "             4              5              6              7               8    \\\n",
       "0   9.0597715378   3.4204881191  -2.2218639851  -0.9368617535    4.6807227135   \n",
       "1 -96.7137527466 138.8414306641 -76.1784362793 -37.1504478455   77.4786834717   \n",
       "2  86.8657608032 -99.9413833618 -94.3557434082 -35.7667655945 -103.2975463867   \n",
       "3 -99.1568908691 -38.8158988953 -70.0380783081 -80.8727645874  -86.2410125732   \n",
       "4  -1.1457815170  -2.3453042507  -0.4327180088   0.9685511589    1.2786015272   \n",
       "\n",
       "              9    ...            118            119             120  \\\n",
       "0    0.0228122752  ...   1.3902884722  -2.5164117813    6.0603146553   \n",
       "1  102.9104461670  ... 106.6632690430  32.4698562622   66.7706451416   \n",
       "2 -206.5962371826  ... 174.2192535400 207.1479492188 -160.1919097900   \n",
       "3    5.9249396324  ... 265.2242736816  98.8958892822  248.7752227783   \n",
       "4   -2.0608532429  ...  -1.8692209721   1.3978652954    0.8398435712   \n",
       "\n",
       "             121            122             123             124  \\\n",
       "0  -0.6544523239  -0.8754109144   -1.3680120707    0.5099500418   \n",
       "1  84.0036621094 107.8564758301  -17.8615455627 -122.0732040405   \n",
       "2 -72.0796051025 231.8607177734  160.5847473145   51.1832656860   \n",
       "3 395.5150756836 -30.9516849518 -219.1926727295  -90.7720031738   \n",
       "4  -1.8602241278   2.5099594593   -1.8832107782    2.1124527454   \n",
       "\n",
       "              125             126             127  \n",
       "0   -1.8036836386    4.5414137840    0.6198633909  \n",
       "1 -141.7993011475    8.2321844101  -47.7921752930  \n",
       "2    3.2517094612  -20.8090553284  -19.6302394867  \n",
       "3  110.5933151245 -107.1297378540 -313.3342895508  \n",
       "4    1.3380315304   -2.2021000385    0.2801496387  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show result\n",
    "embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0b8cf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with 196591 rows and 128 columns\n"
     ]
    }
   ],
   "source": [
    "print(f'DataFrame with {embedding_df.shape[0]} rows and {embedding_df.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ffcea",
   "metadata": {},
   "source": [
    "The next step is to create a single feature vector for each *pair* of users in our sample set. This vector needs to describe the relationship between the two users. The **Hadamard Product** is a simple yet effective method that should capture the interaction and agreement between two users embedding along each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3a84828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient vectorized Hadamard Product\n",
    "samples_df = pd.DataFrame(combined_samples, columns=['source', 'destination'])\n",
    "source_vectors = embedding_df.loc[(samples_df['source'])].values\n",
    "destination_vectors = embedding_df.loc[samples_df['destination']].values\n",
    "hadamard_product = source_vectors * destination_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a12fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pair Features dataframe with multi-index\n",
    "pair_features_df = pd.DataFrame(\n",
    "    hadamard_product,\n",
    "    index=pd.MultiIndex.from_frame(samples_df),\n",
    "    columns=[f'embed_hadamard_{i}' for i in range(hadamard_product.shape[1])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d587d1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>embed_hadamard_0</th>\n",
       "      <th>embed_hadamard_1</th>\n",
       "      <th>embed_hadamard_2</th>\n",
       "      <th>embed_hadamard_3</th>\n",
       "      <th>embed_hadamard_4</th>\n",
       "      <th>embed_hadamard_5</th>\n",
       "      <th>embed_hadamard_6</th>\n",
       "      <th>embed_hadamard_7</th>\n",
       "      <th>embed_hadamard_8</th>\n",
       "      <th>embed_hadamard_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_hadamard_118</th>\n",
       "      <th>embed_hadamard_119</th>\n",
       "      <th>embed_hadamard_120</th>\n",
       "      <th>embed_hadamard_121</th>\n",
       "      <th>embed_hadamard_122</th>\n",
       "      <th>embed_hadamard_123</th>\n",
       "      <th>embed_hadamard_124</th>\n",
       "      <th>embed_hadamard_125</th>\n",
       "      <th>embed_hadamard_126</th>\n",
       "      <th>embed_hadamard_127</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>979.6477661133</td>\n",
       "      <td>64.4793167114</td>\n",
       "      <td>42.4733657837</td>\n",
       "      <td>-42.4742126465</td>\n",
       "      <td>-876.2045288086</td>\n",
       "      <td>474.9054565430</td>\n",
       "      <td>169.2581176758</td>\n",
       "      <td>34.8048324585</td>\n",
       "      <td>362.6562194824</td>\n",
       "      <td>2.3476214409</td>\n",
       "      <td>...</td>\n",
       "      <td>148.2927093506</td>\n",
       "      <td>-81.7075271606</td>\n",
       "      <td>404.6511230469</td>\n",
       "      <td>-54.9763908386</td>\n",
       "      <td>-94.4187393188</td>\n",
       "      <td>24.4348106384</td>\n",
       "      <td>-62.2512359619</td>\n",
       "      <td>255.7610778809</td>\n",
       "      <td>37.3857574463</td>\n",
       "      <td>-29.6246204376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188.9392089844</td>\n",
       "      <td>115.4695739746</td>\n",
       "      <td>589.5510864258</td>\n",
       "      <td>99.1190414429</td>\n",
       "      <td>786.9839477539</td>\n",
       "      <td>-341.8483276367</td>\n",
       "      <td>209.6456298828</td>\n",
       "      <td>33.5085144043</td>\n",
       "      <td>-483.5071716309</td>\n",
       "      <td>-4.7129302025</td>\n",
       "      <td>...</td>\n",
       "      <td>242.2150268555</td>\n",
       "      <td>-521.2695312500</td>\n",
       "      <td>-970.8133544922</td>\n",
       "      <td>47.1726646423</td>\n",
       "      <td>-202.9734039307</td>\n",
       "      <td>-219.6818695068</td>\n",
       "      <td>26.1009082794</td>\n",
       "      <td>-5.8650550842</td>\n",
       "      <td>-94.5025329590</td>\n",
       "      <td>-12.1680669785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.1266479492</td>\n",
       "      <td>-417.0082702637</td>\n",
       "      <td>-84.0286788940</td>\n",
       "      <td>-40.5347976685</td>\n",
       "      <td>-898.3388061523</td>\n",
       "      <td>-132.7693176270</td>\n",
       "      <td>155.6150817871</td>\n",
       "      <td>75.7666015625</td>\n",
       "      <td>-403.6702575684</td>\n",
       "      <td>0.1351613551</td>\n",
       "      <td>...</td>\n",
       "      <td>368.7382507324</td>\n",
       "      <td>-248.8627777100</td>\n",
       "      <td>1507.6561279297</td>\n",
       "      <td>-258.8457641602</td>\n",
       "      <td>27.0954437256</td>\n",
       "      <td>299.8582153320</td>\n",
       "      <td>-46.2891883850</td>\n",
       "      <td>-199.4753570557</td>\n",
       "      <td>-486.5204772949</td>\n",
       "      <td>-194.2244567871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.6569972038</td>\n",
       "      <td>-2.0574290752</td>\n",
       "      <td>-8.5968608856</td>\n",
       "      <td>-0.3795726001</td>\n",
       "      <td>-10.3805189133</td>\n",
       "      <td>-8.0220851898</td>\n",
       "      <td>0.9614405632</td>\n",
       "      <td>-0.9073985219</td>\n",
       "      <td>5.9847793579</td>\n",
       "      <td>-0.0470127501</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.5987563133</td>\n",
       "      <td>-3.5176045895</td>\n",
       "      <td>5.0897164345</td>\n",
       "      <td>1.2174279690</td>\n",
       "      <td>-2.1972458363</td>\n",
       "      <td>2.5762550831</td>\n",
       "      <td>1.0772453547</td>\n",
       "      <td>-2.4133856297</td>\n",
       "      <td>-10.0006475449</td>\n",
       "      <td>0.1736545116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-177.4321289062</td>\n",
       "      <td>-129.8639068604</td>\n",
       "      <td>180.8720092773</td>\n",
       "      <td>1.5084964037</td>\n",
       "      <td>-1050.4962158203</td>\n",
       "      <td>-81.6159896851</td>\n",
       "      <td>-256.6806945801</td>\n",
       "      <td>16.7166862488</td>\n",
       "      <td>27.0056438446</td>\n",
       "      <td>-3.9036676884</td>\n",
       "      <td>...</td>\n",
       "      <td>-168.0630798340</td>\n",
       "      <td>-548.3483276367</td>\n",
       "      <td>-143.0008087158</td>\n",
       "      <td>-14.3819866180</td>\n",
       "      <td>-111.5149078369</td>\n",
       "      <td>151.4530487061</td>\n",
       "      <td>94.4965515137</td>\n",
       "      <td>-454.1807861328</td>\n",
       "      <td>-446.7528991699</td>\n",
       "      <td>50.4457626343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    embed_hadamard_0  embed_hadamard_1  embed_hadamard_2  \\\n",
       "source destination                                                         \n",
       "0      1              979.6477661133     64.4793167114     42.4733657837   \n",
       "       2              188.9392089844    115.4695739746    589.5510864258   \n",
       "       3              100.1266479492   -417.0082702637    -84.0286788940   \n",
       "       4                7.6569972038     -2.0574290752     -8.5968608856   \n",
       "       5             -177.4321289062   -129.8639068604    180.8720092773   \n",
       "\n",
       "                    embed_hadamard_3  embed_hadamard_4  embed_hadamard_5  \\\n",
       "source destination                                                         \n",
       "0      1              -42.4742126465   -876.2045288086    474.9054565430   \n",
       "       2               99.1190414429    786.9839477539   -341.8483276367   \n",
       "       3              -40.5347976685   -898.3388061523   -132.7693176270   \n",
       "       4               -0.3795726001    -10.3805189133     -8.0220851898   \n",
       "       5                1.5084964037  -1050.4962158203    -81.6159896851   \n",
       "\n",
       "                    embed_hadamard_6  embed_hadamard_7  embed_hadamard_8  \\\n",
       "source destination                                                         \n",
       "0      1              169.2581176758     34.8048324585    362.6562194824   \n",
       "       2              209.6456298828     33.5085144043   -483.5071716309   \n",
       "       3              155.6150817871     75.7666015625   -403.6702575684   \n",
       "       4                0.9614405632     -0.9073985219      5.9847793579   \n",
       "       5             -256.6806945801     16.7166862488     27.0056438446   \n",
       "\n",
       "                    embed_hadamard_9  ...  embed_hadamard_118  \\\n",
       "source destination                    ...                       \n",
       "0      1                2.3476214409  ...      148.2927093506   \n",
       "       2               -4.7129302025  ...      242.2150268555   \n",
       "       3                0.1351613551  ...      368.7382507324   \n",
       "       4               -0.0470127501  ...       -2.5987563133   \n",
       "       5               -3.9036676884  ...     -168.0630798340   \n",
       "\n",
       "                    embed_hadamard_119  embed_hadamard_120  \\\n",
       "source destination                                           \n",
       "0      1                -81.7075271606      404.6511230469   \n",
       "       2               -521.2695312500     -970.8133544922   \n",
       "       3               -248.8627777100     1507.6561279297   \n",
       "       4                 -3.5176045895        5.0897164345   \n",
       "       5               -548.3483276367     -143.0008087158   \n",
       "\n",
       "                    embed_hadamard_121  embed_hadamard_122  \\\n",
       "source destination                                           \n",
       "0      1                -54.9763908386      -94.4187393188   \n",
       "       2                 47.1726646423     -202.9734039307   \n",
       "       3               -258.8457641602       27.0954437256   \n",
       "       4                  1.2174279690       -2.1972458363   \n",
       "       5                -14.3819866180     -111.5149078369   \n",
       "\n",
       "                    embed_hadamard_123  embed_hadamard_124  \\\n",
       "source destination                                           \n",
       "0      1                 24.4348106384      -62.2512359619   \n",
       "       2               -219.6818695068       26.1009082794   \n",
       "       3                299.8582153320      -46.2891883850   \n",
       "       4                  2.5762550831        1.0772453547   \n",
       "       5                151.4530487061       94.4965515137   \n",
       "\n",
       "                    embed_hadamard_125  embed_hadamard_126  embed_hadamard_127  \n",
       "source destination                                                              \n",
       "0      1                255.7610778809       37.3857574463      -29.6246204376  \n",
       "       2                 -5.8650550842      -94.5025329590      -12.1680669785  \n",
       "       3               -199.4753570557     -486.5204772949     -194.2244567871  \n",
       "       4                 -2.4133856297      -10.0006475449        0.1736545116  \n",
       "       5               -454.1807861328     -446.7528991699       50.4457626343  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show result\n",
    "pair_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee198983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free-up memory\n",
    "del embedding_df\n",
    "del samples_df\n",
    "del source_vectors\n",
    "del destination_vectors\n",
    "del hadamard_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a14c4a",
   "metadata": {},
   "source": [
    "### Domain Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e929b3c",
   "metadata": {},
   "source": [
    "Here is a palette of candidate features that were considered for the link prediction model:\n",
    "- **Radius of Gyration**: A measure of a user's typical travel radius, distinguishing \"stayers\" (small radius) from \"travelers\" (large radius).\n",
    "- **Total Check-in Count**: The total number of check-ins for a user, indicating their overall activity level.\n",
    "- **Unique Locations Count**: The number of distinct locations a user has visited, indicating their tendency to explore.\n",
    "- **Jaccard Similarity of Visited Locations**: The overlap in the set of unique locations visited by two users, measuring shared lifestyle and interests.\n",
    "- **Co-check-in Count**: The number of times two users checked into the same location within a short time window (e.g., 1 hour), indicating possible real-world interaction.\n",
    "- **Haversine Distance between User Centroids**: The geographic distance between the average location (centroid) of all check-ins for each user.\n",
    "- **Haversine Distance between Inferred Home Locations**: The geographic distance between the inferred \"home\" location of each user.\n",
    "- **Explicit Topological Features**: Common Neighbors, Jaccard Coefficient, Adamic-Adar, Resource Allocation, Preferential Attachment\n",
    "\n",
    "The first selection will be based on covering each domain of interaction with one feature that is thought to be the best:\n",
    "- **Radius of Gyration**: Analyzed in the EDA, represent the travelers vs. stayers concept and is an indicator of heterophily.\n",
    "- **Haversine Distance between Inferred Home Location**: the core finding in the EDA, represent the geographic proximity and has already been proved a strong indicator of homophily.\n",
    "- **Jaccard Similarity of Visited Locations**: we didn't explicitly explore this in the EDA, but could strongly represent the shared habits for a pair of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8e19ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Original Dataset] - Number of users with at least one check-in: 107092 (54.47%)\n",
      "[Time Train Dataset] - Number of users with at least one check-in: 63526 (32.31%)\n",
      "[Volume Train Dataset] - Number of users with at least one check-in: 94019 (47.82%)\n"
     ]
    }
   ],
   "source": [
    "checkins_per_user = checkins_df['user'].value_counts()\n",
    "print(f'[Original Dataset] - Number of users with at least one check-in: {len(checkins_per_user)} ({len(checkins_per_user)/G.number_of_nodes()*100:.2f}%)')\n",
    "checkins_per_user = t_train_df['user'].value_counts()\n",
    "print(f'[Time Train Dataset] - Number of users with at least one check-in: {len(checkins_per_user)} ({len(checkins_per_user)/G.number_of_nodes()*100:.2f}%)')\n",
    "checkins_per_user = v_train_df['user'].value_counts()\n",
    "print(f'[Volume Train Dataset] - Number of users with at least one check-in: {len(checkins_per_user)} ({len(checkins_per_user)/G.number_of_nodes()*100:.2f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea95ef45",
   "metadata": {},
   "source": [
    "#### Pair-Wise Radius of Gyration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ea39d",
   "metadata": {},
   "source": [
    "We need to recalculate the Radius of Gyration using only the check-ins before the cutoff date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90cdc505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Radius of Gyration with only check-ins before cutoff\n",
    "# Calculate Mean Centroid\n",
    "users_mean_centroids = t_train_df.groupby('user').agg(\n",
    "    mean_centroid_latitude=('latitude', 'mean'),\n",
    "    mean_centroid_longitude=('longitude', 'mean')\n",
    ")\n",
    "\n",
    "# Merge Mean Centroid with check-ins dataframe\n",
    "checkins_with_centroids = pd.merge(t_train_df, users_mean_centroids, on='user')\n",
    "checkins_with_centroids = checkins_with_centroids[['user', 'latitude', 'longitude', 'mean_centroid_latitude', 'mean_centroid_longitude']]\n",
    "\n",
    "# Zip to obtain coordinates pairs\n",
    "checkins_coords = list(zip(checkins_with_centroids['latitude'], checkins_with_centroids['longitude']))\n",
    "centroid_coords = list(zip(checkins_with_centroids['mean_centroid_latitude'], checkins_with_centroids['mean_centroid_longitude']))\n",
    "\n",
    "# Efficient vectorized Haversine Distance\n",
    "distances = haversine_vector(checkins_coords, centroid_coords)\n",
    "checkins_with_centroids['sq_distance_from_centroid'] = distances**2\n",
    "\n",
    "# Calculate Radius of Gyration and save in a new dataframe\n",
    "radius_of_gyration = checkins_with_centroids.groupby('user')['sq_distance_from_centroid'].mean().apply(np.sqrt).rename('radius_of_gyration_km')\n",
    "radius_of_gyration.index = radius_of_gyration.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b56a6e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "0    1203.8236124683\n",
       "4     421.4152289762\n",
       "5      49.8019317812\n",
       "9       5.5957428171\n",
       "10      8.4755866231\n",
       "Name: radius_of_gyration_km, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show results\n",
    "radius_of_gyration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3772a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pair-wise feature: Radius of Gyration Absolute Difference\n",
    "samples_df = pd.DataFrame(combined_samples, columns=['source', 'destination'])\n",
    "source_rg_vector = samples_df['source'].map(radius_of_gyration)\n",
    "destination_rg_vector = samples_df['destination'].map(radius_of_gyration)\n",
    "abs_diff_rg = (source_rg_vector - destination_rg_vector).abs()\n",
    "\n",
    "rg_feature_df = pd.DataFrame({\n",
    "    'rg_source': source_rg_vector,\n",
    "    'rg_destination': destination_rg_vector,\n",
    "    'rg_abs_diff': abs_diff_rg\n",
    "})\n",
    "rg_feature_df.index = pd.MultiIndex.from_frame(samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23d5e5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_source          991583\n",
      "rg_destination    1110422\n",
      "rg_abs_diff       1470012\n",
      "dtype: int64 \n",
      "\n",
      "Radius of Gyration absolute difference missing for 1470012 (77.34%) pairs.\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(rg_feature_df.isna().sum(), \"\\n\")\n",
    "\n",
    "rg_na = rg_feature_df.isna().sum().loc['rg_abs_diff']\n",
    "print(f\"Radius of Gyration absolute difference missing for {rg_na} ({rg_na/len(combined_samples)*100:.4}%) pairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6001e20b",
   "metadata": {},
   "source": [
    "The **Radius of Gyration (RoG)** was calculated for all users based on their activity before the time-based cutoff date. As expected, and as a direct consequence of the network's growth, only 32.3% of the total users had check-in data within this period.\n",
    "\n",
    "We now need to deal with the presence of numerous missing values due to having many users not active on the platform in this time range. To treat this information as a predictive signal rather than a data problem, we engineered a dedicated categorical feature, `activity_status`, to explicitly describe the activity state of each pair (`Both Active`, `Source Active Only`, etc.). This allows the model to learn distinct patterns for each scenario. With a feature that gives context the the RoG values, all the NaN can now be filled with zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63468c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NaN values\n",
    "rg_feature_df['rg_source'] = rg_feature_df['rg_source'].fillna(0)\n",
    "rg_feature_df['rg_destination'] = rg_feature_df['rg_destination'].fillna(0)\n",
    "\n",
    "rg_feature_df['rg_abs_diff'] = (rg_feature_df['rg_source'] - rg_feature_df['rg_destination']).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6e71624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rg_source</th>\n",
       "      <th>rg_destination</th>\n",
       "      <th>rg_abs_diff</th>\n",
       "      <th>activity_status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>source_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>source_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>source_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>421.4152289762</td>\n",
       "      <td>782.4083834921</td>\n",
       "      <td>both_have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>49.8019317812</td>\n",
       "      <td>1154.0216806871</td>\n",
       "      <td>both_have</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         rg_source  rg_destination     rg_abs_diff  \\\n",
       "source destination                                                   \n",
       "0      1           1203.8236124683    0.0000000000 1203.8236124683   \n",
       "       2           1203.8236124683    0.0000000000 1203.8236124683   \n",
       "       3           1203.8236124683    0.0000000000 1203.8236124683   \n",
       "       4           1203.8236124683  421.4152289762  782.4083834921   \n",
       "       5           1203.8236124683   49.8019317812 1154.0216806871   \n",
       "\n",
       "                   activity_status  \n",
       "source destination                  \n",
       "0      1               source_only  \n",
       "       2               source_only  \n",
       "       3               source_only  \n",
       "       4                 both_have  \n",
       "       5                 both_have  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add categorical feature for context\n",
    "source_is_active = samples_df['source'].isin(radius_of_gyration.index)\n",
    "destination_is_active = samples_df['destination'].isin(radius_of_gyration.index)\n",
    "\n",
    "conditions = [\n",
    "    source_is_active & destination_is_active,\n",
    "    source_is_active & ~destination_is_active,\n",
    "    ~source_is_active & destination_is_active,\n",
    "    ~source_is_active & ~destination_is_active\n",
    "]\n",
    "choices = ['both_have', 'source_only', 'dest_only', 'neither_have']\n",
    "\n",
    "activity_status = np.select(conditions, choices, default='Error')\n",
    "\n",
    "rg_feature_df['activity_status'] = activity_status\n",
    "rg_feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "233f4dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rg_source</th>\n",
       "      <th>rg_destination</th>\n",
       "      <th>rg_abs_diff</th>\n",
       "      <th>rg_status_both_have</th>\n",
       "      <th>rg_status_dest_only</th>\n",
       "      <th>rg_status_neither_have</th>\n",
       "      <th>rg_status_source_only</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>421.4152289762</td>\n",
       "      <td>782.4083834921</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1203.8236124683</td>\n",
       "      <td>49.8019317812</td>\n",
       "      <td>1154.0216806871</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         rg_source  rg_destination     rg_abs_diff  \\\n",
       "source destination                                                   \n",
       "0      1           1203.8236124683    0.0000000000 1203.8236124683   \n",
       "       2           1203.8236124683    0.0000000000 1203.8236124683   \n",
       "       3           1203.8236124683    0.0000000000 1203.8236124683   \n",
       "       4           1203.8236124683  421.4152289762  782.4083834921   \n",
       "       5           1203.8236124683   49.8019317812 1154.0216806871   \n",
       "\n",
       "                    rg_status_both_have  rg_status_dest_only  \\\n",
       "source destination                                             \n",
       "0      1                          False                False   \n",
       "       2                          False                False   \n",
       "       3                          False                False   \n",
       "       4                           True                False   \n",
       "       5                           True                False   \n",
       "\n",
       "                    rg_status_neither_have  rg_status_source_only  \n",
       "source destination                                                 \n",
       "0      1                             False                   True  \n",
       "       2                             False                   True  \n",
       "       3                             False                   True  \n",
       "       4                             False                  False  \n",
       "       5                             False                  False  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding categorical feature\n",
    "rg_feature_df = pd.get_dummies(rg_feature_df, columns=['activity_status'], prefix='rg_status')\n",
    "rg_feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd8b435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add results to the complete pair feature dataframe\n",
    "pair_features_df = pair_features_df.join(rg_feature_df.drop(columns=['rg_source', 'rg_destination']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d66db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free-Up Memory\n",
    "del users_mean_centroids\n",
    "del checkins_with_centroids\n",
    "del checkins_coords\n",
    "del centroid_coords\n",
    "del distances\n",
    "del radius_of_gyration\n",
    "del samples_df\n",
    "del source_rg_vector\n",
    "del destination_rg_vector\n",
    "del abs_diff_rg\n",
    "del rg_feature_df\n",
    "del source_is_active\n",
    "del destination_is_active\n",
    "del activity_status\n",
    "del conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf83b3a",
   "metadata": {},
   "source": [
    "#### Haversine Distance between Inferred Home Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5c1a54",
   "metadata": {},
   "source": [
    "Again, all the calculations needs to be redone using only the check-ins before the cutoff date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f6aa385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse code from EDA\n",
    "inferred_home_df = t_train_df.groupby('user').agg(\n",
    "    median_centroid_latitude=('latitude', 'median'),\n",
    "    median_centroid_longitude=('longitude', 'median')\n",
    ")\n",
    "\n",
    "# Heuristic to infer Home Locations\n",
    "home_hours = (t_train_df['check-in_datetime'].dt.hour >= 21) | (t_train_df['check-in_datetime'].dt.hour < 7)\n",
    "\n",
    "# The grid will have 25x25 Kilometers cells\n",
    "lat_step, lon_step = 0.25, 0.25\n",
    "t_train_df['lat_bin'] = (t_train_df['latitude'] / lat_step).astype(int)\n",
    "t_train_df['lon_bin'] = (t_train_df['longitude'] / lon_step).astype(int)\n",
    "\n",
    "# Find the most visited grid cell for each user during home hours\n",
    "home_cells = t_train_df[home_hours]\\\n",
    "    .groupby(['user', 'lat_bin', 'lon_bin'])\\\n",
    "    .size()\\\n",
    "    .reset_index(name='count')\\\n",
    "    .sort_values('count', ascending=False)\\\n",
    "    .drop_duplicates(subset='user')\\\n",
    "    .set_index('user')\\\n",
    "    [['lat_bin', 'lon_bin']]\\\n",
    "    .rename(columns={'lat_bin': 'home_lat_bin', 'lon_bin': 'home_lon_bin'})\n",
    "\n",
    "# Chain operations to calculate the centroid of check-ins within each user's home cell\n",
    "home_cell_centroids = (\n",
    "    t_train_df.join(home_cells, on='user')\n",
    "    .dropna(subset=['home_lat_bin'])\n",
    "    .query('lat_bin == home_lat_bin and lon_bin == home_lon_bin')\n",
    "    .groupby('user')\n",
    "    .agg(\n",
    "        home_cell_centroid_lat=('latitude', 'median'),\n",
    "        home_cell_centroid_lon=('longitude', 'median')\n",
    "    )\n",
    ")\n",
    "\n",
    "inferred_home_df = inferred_home_df.join(home_cell_centroids)\n",
    "inferred_home_df.index = inferred_home_df.index.astype(int)\n",
    "inferred_home_df = inferred_home_df[['home_cell_centroid_lat', 'home_cell_centroid_lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0045af80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "home_cell_centroid_lat    10739\n",
       "home_cell_centroid_lon    10739\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_home_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "955c9788",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.DataFrame(combined_samples, columns=[\"source\", \"destination\"])\n",
    "\n",
    "samples_df = samples_df.join(inferred_home_df, on=\"source\")\n",
    "samples_df = samples_df.rename(columns={\n",
    "    \"home_cell_centroid_lat\": \"source_home_lat\",\n",
    "    \"home_cell_centroid_lon\": \"source_home_lon\",\n",
    "})\n",
    "\n",
    "samples_df = samples_df.join(inferred_home_df, on=\"destination\")\n",
    "samples_df = samples_df.rename(columns={\n",
    "    \"home_cell_centroid_lat\": \"dest_home_lat\",\n",
    "    \"home_cell_centroid_lon\": \"dest_home_lon\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10fd6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df.index = pd.MultiIndex.from_frame(samples_df[[\"source\", \"destination\"]])\n",
    "samples_df = samples_df.drop(columns=[\"source\", \"destination\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50949ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_home_coords = list(zip(samples_df['source_home_lat'], samples_df['source_home_lon']))\n",
    "dest_home_coords = list(zip(samples_df['dest_home_lat'], samples_df['dest_home_lon']))\n",
    "\n",
    "distances = haversine_vector(source_home_coords, dest_home_coords)\n",
    "samples_df['home_distance_km'] = distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1abb90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_home_lat     1060573\n",
      "source_home_lon     1060573\n",
      "dest_home_lat       1201301\n",
      "dest_home_lon       1201301\n",
      "home_distance_km    1539456\n",
      "dtype: int64 \n",
      "\n",
      "Home Distance missing for 1539456 (81.0%) pairs.\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(samples_df.isna().sum(), \"\\n\")\n",
    "\n",
    "home_dist_na = samples_df.isna().sum().loc['home_distance_km']\n",
    "print(f\"Home Distance missing for {home_dist_na} ({home_dist_na/len(combined_samples)*100:.4}%) pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "387a59b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_has_home = samples_df['source_home_lat'].notna()\n",
    "dest_has_home = samples_df['dest_home_lat'].notna()\n",
    "\n",
    "conditions = [\n",
    "    source_has_home & dest_has_home,\n",
    "    source_has_home & ~dest_has_home,\n",
    "    ~source_has_home & dest_has_home,\n",
    "    ~source_has_home & ~dest_has_home\n",
    "]\n",
    "\n",
    "choices = ['both_have', 'source_only', 'dest_only', 'neither_have']\n",
    "samples_df['home_status'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374771a",
   "metadata": {},
   "source": [
    "The `home_distance_km` column now contains the calculated distances for pairs where both users had an inferred home, and NaN for all other pairs. A simple imputation with zero would be misleading, as it would imply that users with no inferred home live at the same location. Therefore, a more neutral and statistically robust approach is chosen: the missing distance values are imputed using the **median** of all the calculated distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22942e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Home Distance:  858.9177190455824\n"
     ]
    }
   ],
   "source": [
    "# Impute the missing home distance values with the median of the distances\n",
    "# TODO: could also try to impute with a very large distance\n",
    "median_distance = samples_df['home_distance_km'].median()\n",
    "samples_df['home_distance_km'] = samples_df['home_distance_km'].fillna(median_distance)\n",
    "\n",
    "print(\"Median Home Distance: \", median_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b16df100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding categorical feature\n",
    "samples_df = pd.get_dummies(samples_df, columns=['home_status'], prefix='home_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d41fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add results to the complete pair feature dataframe\n",
    "pair_features_df = pair_features_df.join(samples_df.drop(columns=['source_home_lat', 'source_home_lon', 'dest_home_lat', 'dest_home_lon']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db694820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free-Up Memory\n",
    "del inferred_home_df\n",
    "del home_cells\n",
    "del home_hours\n",
    "del home_cell_centroids\n",
    "del samples_df\n",
    "del source_home_coords\n",
    "del dest_home_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e302a",
   "metadata": {},
   "source": [
    "#### Jaccard Similarity of Visited Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67df0cd4",
   "metadata": {},
   "source": [
    "This is a new introduced feature that we didn't considered in the EDA phase. The goal here is to measure shared lifestyle and interests. We hypothesize that users who frequent the same set of locations, are more likely to be friends. The Jaccard Similarity of their visited location sets provides an intuitive measure of this behavioral overlap.\n",
    "\n",
    "The similarity alone can be a weak signal if it's based on few shared location, but could be a strong one if it's based on many shared locations.\n",
    "The initial idea was to weight the similarity with the visited location count, but having a nonlinear model like GBM we can give the model the raw components and let it discover the complex interactions itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5852704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of users - visited locations\n",
    "user_location_sets = t_train_df.groupby('user')['location_id'].apply(set)\n",
    "user_location_dict = user_location_sets.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6d7f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Location Overlap function\n",
    "def _location_overlap(set1, set2):\n",
    "    intersection_size = len(set1.intersection(set2))\n",
    "    union_size = len(set1.union(set2))\n",
    "\n",
    "    if union_size == 0:\n",
    "        return 0.0, intersection_size, union_size\n",
    "\n",
    "    return (intersection_size / union_size), intersection_size, union_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1fd7acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>jaccard_similarity_locations</th>\n",
       "      <th>intersect_locations</th>\n",
       "      <th>unions_locations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0294117647</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    jaccard_similarity_locations  intersect_locations  \\\n",
       "source destination                                                      \n",
       "0      1                            0.0000000000                    0   \n",
       "       2                            0.0000000000                    0   \n",
       "       3                            0.0000000000                    0   \n",
       "       4                            0.0294117647                    3   \n",
       "       5                            0.0000000000                    0   \n",
       "\n",
       "                    unions_locations  \n",
       "source destination                    \n",
       "0      1                          34  \n",
       "       2                          34  \n",
       "       3                          34  \n",
       "       4                         102  \n",
       "       5                          57  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Jaccard Similarity using list comprehensions\n",
    "samples_df = pd.DataFrame(combined_samples, columns=[\"source\", \"destination\"])\n",
    "\n",
    "locations_overlap_data = [\n",
    "    _location_overlap(user_location_dict.get(source, set()), user_location_dict.get(destination, set()))\n",
    "    for source, destination in zip(samples_df['source'], samples_df['destination'])\n",
    "]\n",
    "\n",
    "jaccard, intersect_sizes, union_sizes = zip(*locations_overlap_data)\n",
    "\n",
    "jaccard_feature_df = pd.DataFrame({\n",
    "    'jaccard_similarity_locations': jaccard,\n",
    "    'intersect_locations': intersect_sizes,\n",
    "    'unions_locations': union_sizes\n",
    "})\n",
    "\n",
    "jaccard_feature_df.index = pd.MultiIndex.from_frame(samples_df)\n",
    "\n",
    "jaccard_feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0cc3d2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jaccard_similarity_locations    0\n",
       "intersect_locations             0\n",
       "unions_locations                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaNs\n",
    "jaccard_feature_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "851781f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 110675 (5.82%) pairs with locations similarity >0.\n",
      "There are 1789979 (94.18%) pairs with locations similarity =0.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_similarity_locations</th>\n",
       "      <th>intersect_locations</th>\n",
       "      <th>unions_locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1900654.0000000000</td>\n",
       "      <td>1900654.0000000000</td>\n",
       "      <td>1900654.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0019025140</td>\n",
       "      <td>0.2376182093</td>\n",
       "      <td>56.9806692854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0141596191</td>\n",
       "      <td>2.1730818325</td>\n",
       "      <td>125.3736290866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>14.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>60.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>445.0000000000</td>\n",
       "      <td>2988.0000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_similarity_locations  intersect_locations   unions_locations\n",
       "count            1900654.0000000000   1900654.0000000000 1900654.0000000000\n",
       "mean                   0.0019025140         0.2376182093      56.9806692854\n",
       "std                    0.0141596191         2.1730818325     125.3736290866\n",
       "min                    0.0000000000         0.0000000000       0.0000000000\n",
       "25%                    0.0000000000         0.0000000000       0.0000000000\n",
       "50%                    0.0000000000         0.0000000000      14.0000000000\n",
       "75%                    0.0000000000         0.0000000000      60.0000000000\n",
       "max                    1.0000000000       445.0000000000    2988.0000000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview of the results\n",
    "sim_not_zero = len(jaccard_feature_df[jaccard_feature_df['jaccard_similarity_locations'] > 0])\n",
    "sim_zero = len(jaccard_feature_df[jaccard_feature_df['jaccard_similarity_locations'] == 0])\n",
    "\n",
    "print(f\"There are {sim_not_zero} ({sim_not_zero/len(jaccard_feature_df)*100:.2f}%) pairs with locations similarity >0.\")\n",
    "print(f\"There are {sim_zero} ({sim_zero/len(jaccard_feature_df)*100:.2f}%) pairs with locations similarity =0.\")\n",
    "\n",
    "jaccard_feature_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa92574",
   "metadata": {},
   "source": [
    "As was to be expected the vast majority of pairs don't have similar visited location, because the data is sparse from all over the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9040d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add results to the complete pair feature dataframe\n",
    "pair_features_df = pair_features_df.join(jaccard_feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37112da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free-Up Memory\n",
    "del jaccard_feature_df\n",
    "del locations_overlap_data\n",
    "del samples_df\n",
    "del user_location_sets\n",
    "del user_location_dict\n",
    "del jaccard, intersect_sizes, union_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58aa37",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c71773df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_features_df['is_friend'] = samples_labels\n",
    "\n",
    "output_path = \"data/engineered_features/final_modeling_dataset.parquet\"\n",
    "\n",
    "pair_features_df.to_parquet(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a545cc2",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79eea9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_df = pd.read_parquet(\"data/engineered_features/final_modeling_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c67965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1520523, 141)\n",
      "X_test shape:  (380131, 141)\n"
     ]
    }
   ],
   "source": [
    "# Final Train/Test Split\n",
    "X = modeling_df.drop(columns=['is_friend'])\n",
    "y = modeling_df['is_friend']\n",
    "\n",
    "# Perform the 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape:  {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6661e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del modeling_df, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6882191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 760262, number of negative: 760261\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.584765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 33740\n",
      "[LightGBM] [Info] Number of data points in the train set: 1520523, number of used features: 141\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000001\n",
      "[LightGBM] [Info] Start training from score 0.000001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(objective=&#x27;binary&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves&nbsp;</td>\n",
       "            <td class=\"value\">31</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin&nbsp;</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples&nbsp;</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LGBMClassifier(objective='binary', random_state=42)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(objective='binary', random_state=42)\n",
    "lgbm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc5140b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm.predict_proba(X_test)[:, 1]\n",
    "score = average_precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f9b5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8240295703580968\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0757c920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the parameter distribution\n",
    "# This is a wide search space for Randomized Search\n",
    "param_dist = {\n",
    "    'n_estimators': [200, 400, 600, 800, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'num_leaves': [15, 31, 63, 127], # Specific to LightGBM, related to max_depth\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# 2. Initialize the GBM Classifier\n",
    "# Using LightGBM is much faster than scikit-learn's default GBM\n",
    "lgbm = LGBMClassifier(objective='binary', random_state=42)\n",
    "\n",
    "# 3. Set up RandomizedSearchCV\n",
    "# n_iter: number of parameter settings that are sampled. A trade-off between runtime and quality.\n",
    "# cv: number of cross-validation folds.\n",
    "# scoring='roc_auc': The best metric for this kind of problem.\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50, # Try 50 different combinations\n",
    "    cv=3,      # Use 3-fold cross-validation\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1, # Use all available CPU cores\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. Run the search on your training data\n",
    "# X_train and y_train are from your train-test split of the final feature matrix\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# 5. Get the best parameters\n",
    "print(\"\\nBest parameters found: \", random_search.best_params_)\n",
    "print(\"Best ROC AUC score on validation data: \", random_search.best_score_)\n",
    "\n",
    "# Store the best estimator for the next steps\n",
    "best_gbm = random_search.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_env_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
